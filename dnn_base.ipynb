{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Conv2D, Dense, Dropout, BatchNormalization, ReLU, DepthwiseConv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Add\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# MNISTデータを加工する\n",
    "x_train  = x_train.reshape(60000, 28*28)\n",
    "x_test   = x_test.reshape(10000, 28*28)\n",
    "\n",
    "x_train  = x_train.astype('float32')\n",
    "x_test   = x_test.astype('float32')\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "y_train  = keras.utils.to_categorical(y_train, 10)\n",
    "y_test   = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BaseModel():\n",
    "    inputs = Input(shape=(784,), name='input')\n",
    "\n",
    "    x = Dense(512, name='layer1')(inputs)\n",
    "    x = Activation('relu', name='activation1')(x)\n",
    "    # x = Dropout(0.25, name='dropout1')(x)\n",
    "\n",
    "    x = Dense(256, name='layer2')(x)\n",
    "    x = Activation('relu', name='activation2')(x)\n",
    "    # x = Dropout(0.20, name='dropout2')(x)\n",
    "\n",
    "    x = Dense(128, name='layer3')(x)\n",
    "    x = Activation('relu', name='activation3')(x)     \n",
    "    # x = Dropout(0.20, name='dropout3')(x)\n",
    "\n",
    "    x = Dense(64, name='layer4')(x)\n",
    "    x = Activation('relu', name='activation4')(x)    \n",
    "    # x = Dropout(0.20, name='dropout4')(x)\n",
    "\n",
    "    x = Dense(10, name='layer5')(x)\n",
    "    x = Activation('softmax', name='activation5')(x)        \n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x, name=\"base_mnist\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0709 19:11:29.128342 139743606441728 deprecation_wrapper.py:119] From /home/uchiumi/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0709 19:11:29.140880 139743606441728 deprecation_wrapper.py:119] From /home/uchiumi/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation1 (Activation)     (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation2 (Activation)     (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation3 (Activation)     (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation4 (Activation)     (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation5 (Activation)     (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 575,050\n",
      "Trainable params: 575,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0709 19:11:34.064910 139743606441728 deprecation_wrapper.py:119] From /home/uchiumi/.local/lib/python3.5/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0709 19:11:34.081507 139743606441728 deprecation_wrapper.py:119] From /home/uchiumi/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0709 19:11:34.194876 139743606441728 deprecation.py:323] From /home/uchiumi/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0709 19:11:34.235190 139743606441728 deprecation_wrapper.py:119] From /home/uchiumi/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0709 19:11:34.321000 139743606441728 deprecation_wrapper.py:119] From /home/uchiumi/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.2059 - acc: 0.9376\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0929 - acc: 0.9723\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0658 - acc: 0.9799\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0534 - acc: 0.9841\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0455 - acc: 0.9860\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0380 - acc: 0.9887\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0325 - acc: 0.9902\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0241 - acc: 0.9928\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0225 - acc: 0.9931\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0225 - acc: 0.9933\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0166 - acc: 0.9949\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0189 - acc: 0.9947\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0154 - acc: 0.9957\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0180 - acc: 0.9952\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0148 - acc: 0.9957\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0143 - acc: 0.9958\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0151 - acc: 0.9962\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0128 - acc: 0.9964\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0134 - acc: 0.9964\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0107 - acc: 0.9970\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0153 - acc: 0.9963\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0118 - acc: 0.9972\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0114 - acc: 0.9970\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0120 - acc: 0.9971\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0131 - acc: 0.9970\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0129 - acc: 0.9967\n",
      "Epoch 28/30\n",
      "20416/60000 [=========>....................] - ETA: 5s - loss: 0.0098 - acc: 0.9975"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"loss (test) :\", test_loss)\n",
    "print(\"acc  (test) :\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kerasで中間層の出力\n",
    "\n",
    "```python\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "model = ...  # create the original model\n",
    "\n",
    "layer_name = 'my_layer'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "layer1\n",
      "activation1\n",
      "layer2\n",
      "activation2\n",
      "layer3\n",
      "activation3\n",
      "layer4\n",
      "activation4\n",
      "layer5\n",
      "activation5\n"
     ]
    }
   ],
   "source": [
    "for lay in model.layers: print(lay.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_data (60000, 784)\n",
      "layer1 (60000, 256)\n",
      "activation1 (60000, 256)\n",
      "layer2 (60000, 256)\n",
      "activation2 (60000, 256)\n",
      "layer3 (60000, 256)\n",
      "activation3 (60000, 256)\n",
      "layer4 (60000, 256)\n",
      "activation4 (60000, 256)\n",
      "layer5 (60000, 10)\n",
      "activation5 (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# intermediate layer output\n",
    "# --------------------------\n",
    "\n",
    "in_data = x_train\n",
    "print(\"in_data\", x_train.shape)\n",
    "\n",
    "layer_name = \"layer1\"\n",
    "m = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "layer1_output = m.predict(in_data)\n",
    "print(layer_name, layer1_output.shape)\n",
    "\n",
    "layer_name = \"activation1\"\n",
    "m = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "activation1_output = m.predict(in_data)\n",
    "print(layer_name, activation1_output.shape)\n",
    "\n",
    "layer_name = \"layer2\"\n",
    "m = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "layer2_output = m.predict(in_data)\n",
    "print(layer_name, layer2_output.shape)\n",
    "\n",
    "layer_name = \"activation2\"\n",
    "m = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "activation2_output = m.predict(in_data)\n",
    "print(layer_name, activation2_output.shape)\n",
    "\n",
    "layer_name = \"layer3\"\n",
    "m = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "layer3_output = m.predict(in_data)\n",
    "print(layer_name, layer3_output.shape)\n",
    "\n",
    "layer_name = \"activation3\"\n",
    "m = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "activation3_output = m.predict(in_data)\n",
    "print(layer_name, activation3_output.shape)\n",
    "\n",
    "layer_name = \"layer4\"\n",
    "m = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "layer4_output = m.predict(in_data)\n",
    "print(layer_name, layer4_output.shape)\n",
    "\n",
    "layer_name = \"activation4\"\n",
    "m = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "activation4_output = m.predict(in_data)\n",
    "print(layer_name, activation4_output.shape)\n",
    "\n",
    "layer_name = \"layer5\"\n",
    "m = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "layer5_output = m.predict(in_data)\n",
    "print(layer_name, layer5_output.shape)\n",
    "\n",
    "layer_name = \"activation5\"\n",
    "m = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "activation5_output = m.predict(in_data)\n",
    "print(layer_name, activation5_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/dnn_base/in_data', in_data)\n",
    "\n",
    "np.save('data/dnn_base/layer1_output', layer1_output)\n",
    "np.save('data/dnn_base/layer2_output', layer2_output)\n",
    "np.save('data/dnn_base/layer3_output', layer3_output)\n",
    "np.save('data/dnn_base/layer4_output', layer4_output)\n",
    "np.save('data/dnn_base/layer5_output', layer5_output)\n",
    "\n",
    "np.save('data/dnn_base/activation1_output', activation1_output)\n",
    "np.save('data/dnn_base/activation2_output', activation2_output)\n",
    "np.save('data/dnn_base/activation3_output', activation3_output)\n",
    "np.save('data/dnn_base/activation4_output', activation4_output)\n",
    "np.save('data/dnn_base/activation5_output', activation5_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
